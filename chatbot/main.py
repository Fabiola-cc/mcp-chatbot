# src/chatbot/main.py
import os
import sys
from datetime import datetime
from dotenv import load_dotenv

from ollama_client import OllamaClient
from session_manager import SessionManager
from logger import InteractionLogger

class MCPChatbot:
    def __init__(self):
        """Inicializa el chatbot con todos sus componentes"""
        load_dotenv()
        
        try:
            self.ollama = OllamaClient()
            self.session = SessionManager()
            self.logger = InteractionLogger()
            self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            print("ğŸ¤– Inicializando chatbot MCP con Ollama...")
            print("âœ… ConexiÃ³n con Ollama establecida")
                
        except Exception as e:
            print(f"âŒ Error inicializando chatbot: {str(e)}")
            print("\nğŸ’¡ Soluciones:")
            print("1. Verificar que Ollama estÃ© instalado: curl -fsSL https://ollama.com/install.sh | sh")
            print("2. Iniciar Ollama: ollama serve")
            print("3. Descargar un modelo: ollama pull llama3.2:3b")
            sys.exit(1)
    
    def show_welcome_message(self):
        """Muestra mensaje de bienvenida y comandos disponibles"""
        print("\n" + "="*60)
        print("ğŸ¤– CHATBOT MCP LOCAL - Â¡Bienvenido!")
        print("ğŸ  Usando modelo local con Ollama (100% privado)")
        print("="*60)
        print("ğŸ’¬ Puedes hacer preguntas normales o usar comandos especiales:")
        print()
        print("ğŸ“‹ COMANDOS ESPECIALES:")
        print("  /help     - Mostrar esta ayuda")
        print("  /log      - Mostrar log de interacciones")
        print("  /mcp      - Mostrar interacciones MCP")
        print("  /stats    - Mostrar estadÃ­sticas de la sesiÃ³n")
        print("  /context  - Mostrar resumen del contexto actual")
        print("  /clear    - Limpiar contexto de conversaciÃ³n")
        print("  /save     - Guardar sesiÃ³n actual")
        print("  /quit     - Salir del chatbot")
        print()
        print("ğŸ”§ FUNCIONALIDADES MCP (prÃ³ximamente):")
        print("  - Filesystem operations (crear/leer archivos)")
        print("  - Git operations (init, add, commit)")
        print("  - Servidor personalizado")
        print(f"\nğŸ§  Modelo actual: {self.ollama.model_name}")
        available_models = self.ollama.list_available_models()
        if len(available_models) > 1:
            print(f"ğŸ“¦ Modelos disponibles: {', '.join(available_models)}")
        print("="*60)
    
    def process_special_command(self, command: str) -> bool:
        """
        Procesa comandos especiales del usuario
        
        Args:
            command: Comando ingresado por el usuario
            
        Returns:
            True si era un comando especial, False si no
        """
        command = command.lower().strip()
        
        if command == '/help':
            self.show_welcome_message()
            return True
            
        elif command == '/log':
            self.logger.show_interaction_log()
            return True
            
        elif command == '/mcp':
            self.logger.show_mcp_interactions()
            return True
            
        elif command == '/stats':
            stats = self.session.get_session_stats()
            mcp_stats = self.logger.get_mcp_stats()
            
            print(f"\nğŸ“Š ESTADÃSTICAS DE SESIÃ“N:")
            print(f"  ğŸ’¬ Total mensajes: {stats['total_messages']}")
            print(f"  ğŸ‘¤ Mensajes usuario: {stats['user_messages']}")
            print(f"  ğŸ¤– Mensajes chatbot: {stats['assistant_messages']}")
            print(f"  â±ï¸  DuraciÃ³n: {stats['session_duration']}")
            print(f"  ğŸ§  Mensajes en contexto: {stats['messages_in_context']}")
            print(f"\nğŸ”§ ESTADÃSTICAS MCP:")
            print(f"  ğŸ“¡ Interacciones totales: {mcp_stats['total_interactions']}")
            print(f"  âœ… Tasa de Ã©xito: {mcp_stats['success_rate']:.1f}%")
            print(f"  ğŸ–¥ï¸  Servidores usados: {', '.join(mcp_stats['servers_used']) if mcp_stats['servers_used'] else 'Ninguno'}")
            
            return True
            
        elif command == '/context':
            self.session.show_context_summary()
            return True
            
        elif command == '/clear':
            self.session.clear_context()
            return True
            
        elif command == '/save':
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"session_{timestamp}.json"
            self.session.save_session(filename)
            return True
            
        elif command == '/quit':
            return True
            
        return False
    
    def process_user_message(self, message: str) -> str:
        """
        Procesa mensaje del usuario y genera respuesta
        
        Args:
            message: Mensaje del usuario
            
        Returns:
            Respuesta del chatbot
        """
        # Por ahora, solo usar Ollama
        # TODO: Detectar si necesita MCP y enrutar apropiadamente
        
        context = self.session.get_context()
        response = self.ollama.send_message(message, context)
        
        return response
    
    
    def run(self):
        """Ejecuta el loop principal del chatbot"""
        self.show_welcome_message()
        
        try:
            while True:
                # Obtener entrada del usuario
                user_input = input(f"\nğŸ‘¤ TÃº: ").strip()
                
                # Verificar si es comando especial
                if user_input.startswith('/'):
                    if self.process_special_command(user_input):
                        if user_input.lower() == '/quit':
                            break
                        continue
                
                # Verificar entrada vacÃ­a
                if not user_input:
                    print("ğŸ’­ Por favor ingresa un mensaje o usa /help para ver comandos")
                    continue
                
                # Registrar entrada del usuario
                self.logger.log_user_input(user_input, self.session_id)
                
                # Procesar mensaje
                print("ğŸ¤” Pensando...")
                response = self.process_user_message(user_input)
                
                # Agregar al contexto
                self.session.add_message("user", user_input)
                self.session.add_message("assistant", response)
                
                # Registrar respuesta
                estimated_tokens = self.ollama.estimate_tokens(response)
                self.logger.log_anthropic_response(response, estimated_tokens, self.session_id)
                
                # Mostrar respuesta
                print(f"\nğŸ¤– Chatbot: {response}")
                
        except KeyboardInterrupt:
            print("\n\nğŸ›‘ Chatbot interrumpido por el usuario")
        except Exception as e:
            print(f"\nâŒ Error inesperado: {str(e)}")
            self.logger.logger.error(f"Error en loop principal: {str(e)}")
        finally:
            # Guardar sesiÃ³n al salir
            self.session.save_session(f"/sessions{self.session_id}.json")
            print("ğŸ’¾ SesiÃ³n guardada automÃ¡ticamente")
            print("ğŸ‘‹ Â¡Hasta luego!")


def main():
    """FunciÃ³n principal"""
    chatbot = MCPChatbot()
    chatbot.run()


if __name__ == "__main__":
    main()